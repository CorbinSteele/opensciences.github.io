---
layout: journals
title: The Journal
---

<img width=150 align=right
src="/img/open_access.jpg"> The Software
Science Journal (SSJ) provides an international
forum for the evaluation and maturation of software
engineering ideas.

The journal offers electronic and paper publication
of high-quality scholarly articles in all areas of
software engineering. All published papers are
freely available online.

SSJ has a commitment to rigorous yet rapid
reviewing. Final versions are published
electronically (online ISSN 2375-5768) immediately upon
receipt. Paper volumes are now published and sold 
on demand within Amazon (print ISSN  2375-5741).

SSJ accepts a wide variety of papers, include those
in _traditional_ and _novel_ formats:

+ A _traditional format_ paper is a 2000 to 5000
  word document containing a (1) motivational
  statement followed by (2) some related work then
  (3) a description of the study instruments and (4)
  results from those instruments then (5) a
  discussion of external validity.
+ On the other hand, _novel formats_ can be much
  more varied.  The view of SSJ is that research
  papers contain many _research products_, any of
  which can be separately peer-reviewed and
  published. That list of _research products_
  includes, but is not limited, to the following
  items.

Note that since SSJ papers can be as short as a
single _research product_, these SSJ papers can be
much shorter than other journals. Hence, SSJ can
offer faster review times for these shorter papers.



## Research Products

A (partial) list of research products follows. Note
that an SSJ submission contains one or more of the following:

1.  _Motivational statements_ or reports or challenge
    statements or lists of open issues that prompt an
    analysis;
2.  _Literature reviews_ or annotated bibliographies;
3.  _Study instruments_ such as surveys interview
    scripts, etc;
4.  _Results_ from using the instruments;
5.  _Methodological discussions_ such as threats to external validity;
6.  Any _data_ used in an analysis (either raw from a
    project or some derived product);
7.  Any _scripts_ used to perform the analysis;
8.  _Checklists_ used to design the analysis;
9.  _Hypotheses_ about expected effects in some area;
10. _Statistical tests_ used to analyze results;
11. _Baseline results_ against which new work can be
    compared;
12. _Sampling procedures_ e.g. “how did you choose the
    projects you studied?”;
13. _Patterns_ describing best practices for performing
    this kind of analysis;
14. _Anti-patterns_ describing cautionary tales of
    “gotchas” to avoid when doing this kind of work;
15. _Negative results_ that are anti-patterns, backed up
    by empirical results;
16. _Executable models_ that can generate exemplar data;
    or which offer an executable form of current
    hypotheses;
17. _Tutorial materials:_ guides to help newcomers become
    proficient in the area. Some of these tutorial
    materials may be generated by the researcher and
    others may be collected from other sources.
18. _New results_ that offer guidance on how to best
    handle future problems.
19. _Future work:_ From the results, there many be
    speculations about open issues of future issues that
    might become the motivation for the next round of
    research.
